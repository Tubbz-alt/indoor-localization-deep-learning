\documentclass{standalone}

\begin{document}
In questo capitolo saranno introdotti i concetti fondamentali alla base delle
moderne tecniche di Deep Learning e le strutture matematiche necessarie alla
loro comprensione. \\

\section{Machine Learning}
Il \emph{Machine Learning}, o apprendimento automatico, è un insieme di
tecniche e algoritmi che consente a dei programmi di ``imparare'' a svolgere
un determinato compito sulla base di esperienze pregresse, senza bisogno da
parte del programmatore di specificare come eseguire tali mansioni. 
\subsection{Regressione Lineare}
Un classico esempio di algoritmo di machine learning è quello della regressione
lineare. Scopo dell'algoritmo è predire l'output di una determinata funzione.
Si consideri quindi un vettore $ \bm x \in \mathbb{R}^n $, e un valore scalare
$\hat{y} = \bm \theta^\intercal \bm x$. il vettore $\bm \theta$ introduce i
parametri del modello, mentre $\hat{y}$ ne rappresenta l'output, che è una
funzione lineare di $\bm x$. Siano quindi $ \bm x_1, \bm x_2, \dotsc, \bm x_m $
dei vettori in $\mathbb{R}^n$ e  $ y_1, y_2, \dotsc, y_m $ i corrispettivi
valori della funzione $f(\bm x_i)$ che stiamo cercando di approssimare.

Perchè la funzione $\hat{y}(\bm x)$ approssimi $f(\bm x)$ è necessario che i
parametri $\bm \theta$ del modello si adattino in modo da minimizzare la differenza
tra l'output prodotto dal modello e la cosiddetta \emph{ground truth}: $y =
f(\bm x)$. A questo scopo si definisce una metrica di errore propria del
processo di apprendimento: l'errore quadratico medio (MSE dall'inglese) 
\begin{equation} \label{eq:mse}
  MSE = \frac{1}{m} \sum_{i=1}^m{(\hat{y} - y_i)^2} 
\end{equation}

Per minimizzare l'errore sul nostro dataset di test è sufficiente porre a zero
la derivata, rispetto a $\bm \theta$, della nostra funzione di costo. Nel caso
della regressione lineare è possibile risolvere l'equazione risultante
ottenendo un sistema di equazioni che prende il nome di 
\emph{normal equations}.
Esistono tuttavia metodi numerici iterativi che si basano sulle informazioni
fornite dal gradiente della funzione di costo che permettono di aggiornare i
parametri del modello cercando di ridurne l'errore, anche nel caso di modelli
non lineari. L'algoritmo su cui si basano molti dei moderni metodi di
apprendimento del Deep Learning è il \emph{gradient descent} o metodo del
gradiente.

Il metodo del gradiente aggiorna i parametri $\bm \theta$ del modello secondo
la seguente regola: 
\begin{equation} \label{eq:grad-up}
  \bm \theta' = \bm \theta - \eta \nabla_{\bm \theta} J(\bm \theta) 
\end{equation}
dove $J(\bm \theta)$ rappresenta la funzione di costo associata al modello,
mentre $\eta$ è un coefficiente chiamato \emph{learning rate}.
%Intuizione gradient descent
Un'interpretazione dell'algoritmo è data dalle informazioni sulla monotonia
ottenute dal gradiente della funzione di costo: per $\eta$ abbastanza piccolo
risulta $J(\bm \theta') \leq J(\bm \theta)$ poichè il gradiente negativo di $J$
determina la direzione di massima decrescita della funzione\cite{goodfellow}.
Ne consegue che applicando ricorsivamente la regola di aggiornamento del metodo
del gradiente, la nostra funzione $\hat{y}$ tenderà ad avvicinarsi alla
funzione originale $y$, minimizzando la funzione di costo.
Possiamo intepretare il coefficiente $\eta$ come la velocità con cui seguire la
pendenza della funzione di errore. \\
{\large TODO: Inserire un'immagine che fornisca un'intuizione del
  funzionamento del gradient descent}

%Gradient descent con MSE e modello lineare
Nel caso di un modello di regressione lineare che usa l'MSE come funzione di
costo, risulta: 
\begin{align*}
  & \forall j \in {1, \dotsc, n}: \\
  \frac{\partial}{\partial\theta_j} MSE &= 
  \frac{\partial}{\partial\theta_j} \frac{1}{m} \sum_{i=1}^m{(\hat{y}_i -
    y_i)^2} \\ 
  %
  &= \frac{\partial}{\partial\theta_j} \frac{1}{m}
  \sum_{i=1}^m{(\bm \theta^\intercal \bm x_i - y_i)^2} \\
  %
  &= \frac{1}{m}
  \sum_{i=1}^m{\frac{\partial}{\partial\theta_j}(\bm \theta^\intercal \bm x_i -
    y_i)^2} \\
  %
  &= \frac{2}{m}
  \sum_{i=1}^m{(\bm \theta^\intercal \bm x_i - y_i)x_i^{(j)}}
\end{align*}
%
Ovvero abbiamo che la regola di aggiornamento è:
$$ \theta'_j = \theta_j - \eta \frac{\partial}{\partial\theta_j} J(\bm \theta)
             = \theta_j - \eta (\frac{2}{m} 
             \sum_{i=1}^m{(\bm \theta^\intercal \bm x_i - y_i)x_i^{(j)}}),
             \quad \forall j \in \{1, \dotsc, n\}
$$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Perceptron}
Il \emph{Perceptron} è il modello che ha posto le basi per le moderne reti
neurali artificiali e il deep learning. Esso prende spunto dalla neurologia,
cercando di imitare il comportamento dei neuroni del cervello umano, con ovvie
limitazioni e senza presunzione di volerne fornire una simulazione accurata del
funzionamento. Una schematizzazione del modello è descritta in Figura
\ref{fig:perceptron}
\begin{figure}[!htp]
  \includetikz{0.9}{./img/perceptron}
  \caption{Schematizzazione del Perceptron}
  \label{fig:perceptron}
\end{figure}

Il perceptron è molto simile al modello di regressione lineare descritto
precedentemente, ma si distingue per un fattore fondamentale: la non linearità.
L'output del perceptron è infatti definito come:
$$\hat{y}(\bm x) = g(\bm \theta^\intercal \bm x)$$
dove $g$ è una funzione \emph{sigmoidea}, cioè una funzione che ha un andamento
a ``S'', con due asintoti orizzontali come in Figura \ref{fig:sigmoid}: di
solito è utilizzata la funzione logistica $\displaystyle g(x) = \frac{1}{1 + e^{-x}}$.
\begin{figure}[!htp]
  \includetikz{0.8}{./img/sigmoid}
  \caption{Funzione sigmoidea $\displaystyle g(x) = \frac{1}{1 + e^{-x}}$ }
  \label{fig:sigmoid}
\end{figure}

Malgrado la nonlinearità del modello, il perceptron non è in grado di
approssimare molte classi di funzioni. È famoso l'esempio della funzione XOR,
la quale non può essere imparata dal perceptron. Per questo motivo è stata
sviluppata un'estensione del modello che prende il nome di \emph{Multi Layer
  Perceptron}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Multi Layer Perceptron}
Il Multi Layer Percepton (MLP) è uno dei modelli più emblematici del Deep
Learning. Esso si basa sui concetti descritti finora ed è la naturale
estensione del perceptron. L'MLP risolve infatti il principale problema del
modello su cui è fondato, essendo in grado di approssimare qualsiasi tipo di
funzione continua con precisione arbitraria, sotto l'assunzione che la
funzione di attivazione sia non polinomiale\cite{universal-approximator}.

L'MLP è un modello di machine learning che fa parte della categoria delle reti
neurali, in quanto è composto da un insieme di neuroni artificiali
(perceptron) disposti su più livelli e interconnessi tra di loro. Una
schematizzazione del modello è fornita in Figura \ref{fig:mlp}.
\begin{figure}[!htp]
  \includetikz{0.9}{./img/mlp}
  \caption{Schematizzazione del Multi Layer Perceptron: in Figura è mostrata
    una rete neurale con $n$ valori di input, un singolo hidden layer con $m$
    neuroni e un solo output. Si noti che non si è limitati ad usare un solo
    neurone di output. Sono omessi per chiarezza i parametri del modello e le
    funzioni di attivazione, riassunte in questo caso all'interno di ogni
    neurone.}
  \label{fig:mlp}
\end{figure}
Nello specifico, l'MLP presenta un primo livello $N$-dimensionale che coincide con il
suo input, un livello di output $M$-dimensionale e una serie arbitraria di
livelli intermedi (\emph{hidden layers}) di ampiezza variabile. Ogni nodo del
livello precedente è connesso con ogni neurone del livello successivo e ogni
neurone del modello si comporta come un singolo perceptron, ovvero esegue una
somma pesata degli input ricevuti dal livello precedente e produce in output il
risultato attraverso una funzione di attivazione non-lineare. Per questo motivo
i parametri del modello, cioè i coefficienti con cui vengono sommati gli input
di ogni nodo, sono uno per ogni connessione. Questo tipo di modelli vengono
anche chiamati \emph{Feed Forward Networks}, in quanto le connessioni tra nodi
sono dirette soltanto verso i livelli direttamente successivi, e mai il
contrario.

Sia $\bm \Theta^\ell$ la matrice dei pesi delle connessioni tra il livello
$\ell-1$ e quello successivo, definita in modo che $ \Theta^\ell_{ij} $
rappresenti il coefficiente relativo alla connessione tra il neurone $i$-esimo
del livello $\ell$ e il neurone $j$-esimo del livello $\ell-1$. Questa
configurazione della matrice dei coefficienti, nonostante sia poco intuitiva,
permette di esprimere l'insieme di valori uscenti da un generico livello $\ell$
sotto forma di prodotto: $ \bm h^\ell = \bm \Theta^\ell \bm h^{\ell-1}$. Se
$L$ è il numero di livelli intermedi della rete neurale, risulta:
\begin{align*}
  o(\bm x) &= \bm \Theta^{L+1} \bm h^L \\
  &= \bm \Theta^{L+1} g( \bm \Theta^L \bm h^{L-1}) \\
  &= \bm \Theta^{L+1} g(\bm \Theta^L g(\dots g(\bm \Theta^1 \bm x)))
\end{align*}
% $$ o(\bm x) = \bm \Theta^{L+1} \bm h^L = \bm \Theta^{L+1} g( \bm \Theta^L \bm
% h^{L-1}) = \bm \Theta^{L+1} g(\bm \Theta^L g(\dots g(\bm \Theta^1 \bm x)))$$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{BackPropagation}
Per utilizzare il metodo del gradiente con una rete neurale Feed Forward, è
necessario calcolare la derivata della funzione di costo del modello. Tuttavia
nell'MLP essa dipende sia dai parametri del livello immediatamente precedente
che da tutti i parametri dei livelli più bassi, per ricorsione. Si può pensare
al BackPropagation come un modo per propagare all'indietro le informazioni
relative all'errore commesso dai nodi di output rispetto ai target del dataset
di addestramento.

L'algoritmo calcola il gradiente della funzione di costo in modo automatico
applicando ricorsivamente lungo il grafo di computazione di $J(\bm \Theta)$ la
``regola della catena'', ovvero la regola di derivazione per le funzioni
composte: $ (f \circ g)' = (f' \circ g)\cdot g' $. Esso sfrutta la tecnica
della programmazione dinamica per evitare di ricalcolare più volte la derivata
di branch comuni dell'albero di computazione, rendendolo di fatto un metodo
molto efficiente.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Attivazione: ReLU}
Come descritto, la funzione di attivazione conferisce al modello la
nonlinearità. Ciò è fondamentale perchè l'MLP riesca ad approssimare funzioni
continue arbitrarie. Se non ci fosse alcuna funzione di attivazione o se questa
fosse lineare rispetto ai parametri del modello, l'output della rete si
potrebbe esprimere come una semplice applicazione lineare, rendendolo di fatto
equivalente a un semplice modello di regressione lineare.

Con l'avvento delle reti neurali profonde e di nuove architetture più
complesse, l'utilizzo delle funzioni di attivazioni logistiche è andato
calando. Una delle cause è il cosiddetto "vanishing gradient", un problema che
insorge nel calcolare numericamente il gradiente della funzione di costo di una
rete neurale con molti livelli. In questo caso l'uso della funzione sigmoidea è
in generale sconsigliato poichè il suo valore ``satura'' a causa dei suoi
asintoti e questo rende la sua derivata prossima a zero. Il metodo del
gradiente risulta quindi poco efficace nell'aggiornare i parametri del modello.
Per questo motivo è stata introdotta la funzione ReLU (dall'inglese
\emph{rectified linear unit}) definita nel modo seguente: 
$g(x) = max\{0, x\}$. L'operazione di rettificazione è mostrata in Figura
\ref{fig:relu}.
\begin{figure}[!htp]
  \includetikz{0.9}{./img/relu}
  \caption{La funzione di attivazione ReLU}
  \label{fig:relu}
\end{figure}

L'output del rettificatore, essendo esso quasi una funzione lineare, mantiene
le informazioni del gradiente in modo migliore rispetto al sigmoide,
rendendo la convergenza del metodo del gradiente più veloce.


\end{document}

