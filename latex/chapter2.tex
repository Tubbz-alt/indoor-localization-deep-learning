\begin{document}
In questo capitolo sono introdotti i concetti fondamentali alla base delle
moderne tecniche di Deep Learning e le strutture matematiche necessarie alla
loro comprensione.

\section{Machine Learning}
Il \emph{Machine Learning}, o apprendimento automatico, è un insieme di
tecniche e algoritmi che consente di scrivere programmi capaci di ``imparare''
a svolgere un determinato compito sulla base di esperienze pregresse, senza
bisogno da parte del programmatore di specificare come eseguire tali mansioni. 
\subsection{Regressione Lineare}
Un classico esempio di algoritmo di machine learning è quello della regressione
lineare. Scopo dell'algoritmo è predire l'output di una determinata funzione.
Si consideri quindi un vettore $ \bm x \in \mathbb{R}^n $, e un valore scalare
$\hat{y} = \bm \theta^\intercal \bm x$. Il vettore $\bm \theta$ introduce i
parametri del modello, mentre $\hat{y}$ ne rappresenta l'output, che è una
funzione lineare di $\bm x$. Siano quindi $ \bm x_1, \bm x_2, \dotsc, \bm x_m $
dei vettori in $\mathbb{R}^n$ e  $ y_1, y_2, \dotsc, y_m $ i corrispettivi
valori della funzione $f(\bm x_i)$ che stiamo cercando di approssimare. Perchè
la funzione $\hat{y}(\bm x)$ approssimi $f(\bm x)$ è necessario che i parametri
$\bm \theta$ del modello si adattino in modo da minimizzare la differenza tra
l'output prodotto dal modello e la cosiddetta \emph{ground truth}: $y = f(\bm
x)$. A questo scopo si definisce una metrica di errore propria del processo di
apprendimento: l'errore quadratico medio (MSE dall'inglese) 
\begin{equation} \label{eq:mse}
  MSE = \frac{1}{m} \sum_{i=1}^m{{(\hat{y} - y_i)}^2} 
\end{equation}

Per minimizzare l'errore commesso sul dataset di test è sufficiente porre a
zero la derivata, rispetto a $\bm \theta$, della funzione di costo. Nel caso
della regressione lineare è possibile risolvere l'equazione risultante
ottenendo un sistema di equazioni che prende il nome di \emph{normal
  equations}. Esistono tuttavia metodi numerici iterativi che si basano sulle
informazioni fornite dal gradiente della funzione di costo e che permettono di
aggiornare i parametri del modello cercando di ridurne l'errore, anche nel caso
di modelli non lineari. L'algoritmo su cui si basano molti dei moderni metodi
di apprendimento del Deep Learning è il \emph{gradient descent} o metodo del
gradiente.

Il metodo del gradiente aggiorna i parametri $\bm \theta$ del modello secondo
la seguente regola: 
\begin{equation} \label{eq:grad-up}
  \bm \theta' = \bm \theta - \eta \nabla_{\bm \theta} J(\bm \theta) 
\end{equation}
dove $J(\bm \theta)$ rappresenta la funzione di costo associata al modello,
mentre $\eta$ è un coefficiente chiamato \emph{learning rate}.
%Intuizione gradient descent
Un'interpretazione dell'algoritmo è fornita dalle informazioni sulla monotonia
ottenute dal gradiente della funzione di costo: per $\eta$ abbastanza piccolo
risulta $J(\bm \theta') \leq J(\bm \theta)$ poichè il gradiente negativo di $J$
determina la direzione di massima decrescita della funzione\cite{goodfellow}.
Ne consegue che applicando ricorsivamente la regola di aggiornamento del metodo
del gradiente, la funzione $\hat{y}$ tenderà ad avvicinarsi alla funzione
originale $y$, minimizzando la funzione di costo.  Possiamo intepretare il
coefficiente $\eta$ come la velocità con cui seguire la pendenza della funzione
di errore.

%Gradient descent con MSE e modello lineare
Nel caso di un modello di regressione lineare che usa l'MSE come funzione di
costo, risulta: 
\begin{align*}
  & \forall j \in {1, \dotsc, n}: \\
  \frac{\partial}{\partial\theta_j} MSE &= 
  \frac{\partial}{\partial\theta_j} \frac{1}{m} \sum_{i=1}^m{{(\hat{y}_i -
    y_i)}^2} \\ 
  %
  &= \frac{\partial}{\partial\theta_j} \frac{1}{m}
  \sum_{i=1}^m{{(\bm \theta^\intercal \bm x_i - y_i)}^2} \\
  %
  &= \frac{1}{m}
  \sum_{i=1}^m{\frac{\partial}{\partial\theta_j}{(\bm \theta^\intercal \bm x_i -
    y_i)}^2} \\
  %
  &= \frac{2}{m}
  \sum_{i=1}^m{(\bm \theta^\intercal \bm x_i - y_i)x_i^{(j)}}
\end{align*}
%
Ovvero abbiamo che la regola di aggiornamento è:
\[ \theta'_j = \theta_j - \eta \frac{\partial}{\partial\theta_j} J(\bm \theta)
             = \theta_j - \eta (\frac{2}{m} 
             \sum_{i=1}^m{(\bm \theta^\intercal \bm x_i - y_i)x_i^{(j)}}),
             \quad \forall j \in \{1, \dotsc, n\}
           \]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Perceptron}
Il \emph{Perceptron} è il modello che ha posto le basi per le moderne reti
neurali artificiali e il deep learning. Esso prende spunto dalla neurologia,
cercando di imitare il comportamento dei neuroni del cervello umano, con ovvie
limitazioni e senza presunzione di volerne fornire una simulazione accurata del
funzionamento. Una schematizzazione del modello è fornita in
Figura~\ref{fig:perceptron}.
Il perceptron è molto simile al modello di regressione lineare descritto
precedentemente, ma si distingue per un fattore fondamentale: la nonlinearità.
L'output del perceptron è infatti definito come:
\[\hat{y}(\bm x) = g(\bm \theta^\intercal \bm x)\]
dove $g$ è una funzione \emph{sigmoidea}, cioè una funzione che ha un andamento
a ``S'', con due asintoti orizzontali come in Figura~\ref{fig:sigmoid}: di
solito è utilizzata la funzione logistica $\displaystyle g(x) = \frac{1}{1 + e^{-x}}$.
\begin{figure}[htp]
  \includetikz{0.9}{./img/perceptron}
  \caption{Schematizzazione del Perceptron}%
  \label{fig:perceptron}
\end{figure}

\begin{figure}[htp]
  \includetikz{0.8}{./img/sigmoid}
  \caption{Funzione sigmoidea $\displaystyle g(x) = \frac{1}{1 + e^{-x}}$ }%
  \label{fig:sigmoid}
\end{figure}

Malgrado la nonlinearità del modello, il perceptron non è in grado di
approssimare molte classi di funzioni. È famoso l'esempio della funzione XOR,
la quale non può essere imparata dal perceptron. Per questo motivo è stata
sviluppata un'estensione del modello che prende il nome di \emph{Multi Layer
  Perceptron}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Multi Layer Perceptron}
Il Multi Layer Percepton (MLP) è uno dei modelli più emblematici del Deep
Learning. Esso si basa sui concetti descritti finora ed è la naturale
estensione del perceptron. L'MLP risolve infatti il problema principale del
modello da cui deriva, essendo in grado di approssimare qualsiasi tipo di
funzione continua con precisione arbitraria, sotto l'assunzione che la funzione
di attivazione utilizzata sia non polinomiale\cite{universal-approximator}.

L'MLP è un modello di machine learning facente parte della categoria delle reti
neurali, in quanto è composto da un insieme di neuroni artificiali (perceptron)
disposti su più livelli e interconnessi tra di loro. Una schematizzazione del
modello è fornita in Figura~\ref{fig:mlp}.
\begin{figure}[htp]
  \includetikz{0.9}{./img/mlp}
  \caption{Schematizzazione del Multi Layer Perceptron: in Figura è mostrata
    una rete neurale con $n$ valori di input, un singolo hidden layer con $m$
    neuroni e un solo output. Si noti che non si è limitati ad usare un solo
    neurone di output. Sono omessi per chiarezza i parametri del modello e le
    funzioni di attivazione, riassunte in questo caso all'interno di ogni
    neurone.%
  }%
  \label{fig:mlp}
\end{figure}
Nello specifico, l'MLP presenta un primo livello $N$-dimensionale che coincide con il
suo input, un livello di output $M$-dimensionale e una serie arbitraria di
livelli intermedi (\emph{hidden layers}) di ampiezza variabile. Ogni nodo del
livello precedente è connesso con ogni neurone del livello successivo e ogni
neurone del modello si comporta come un singolo perceptron, ovvero esegue una
somma pesata degli input ricevuti dal livello precedente e produce in output il
risultato attraverso una funzione di attivazione non-lineare. Per questo motivo
i parametri del modello, cioè i coefficienti con cui vengono sommati gli input
di ogni nodo, sono uno per ogni connessione. Questo tipo di modelli vengono
anche chiamati \emph{Feed Forward Networks}, in quanto le connessioni tra nodi
sono dirette soltanto verso i livelli direttamente successivi, e mai il
contrario.

Sia $\bm \Theta^\ell$ la matrice dei pesi delle connessioni tra il livello
$\ell-1$ e quello successivo, definita in modo che $ \Theta^\ell_{ij} $
rappresenti il coefficiente relativo alla connessione tra il neurone $i$-esimo
del livello $\ell$ e il neurone $j$-esimo del livello $\ell-1$. Questa
configurazione della matrice dei coefficienti permette di esprimere l'insieme
di valori uscenti da un generico livello $\ell$ sotto forma di prodotto: $ \bm
h^\ell = \bm \Theta^\ell \bm h^{\ell-1}$. Se $L$ è il numero di livelli
intermedi della rete neurale, risulta:
\begin{align*}
  o(\bm x) &= \bm \Theta^{L+1} \bm h^L \\
  &= \bm \Theta^{L+1} g( \bm \Theta^L \bm h^{L-1}) \\
  &= \bm \Theta^{L+1} g(\bm \Theta^L g(\dots g(\bm \Theta^1 \bm x)))
\end{align*}
% $$ o(\bm x) = \bm \Theta^{L+1} \bm h^L = \bm \Theta^{L+1} g( \bm \Theta^L \bm
% h^{L-1}) = \bm \Theta^{L+1} g(\bm \Theta^L g(\dots g(\bm \Theta^1 \bm x)))$$
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{BackPropagation}
Per utilizzare il metodo del gradiente con una rete neurale Feed Forward, è
necessario calcolare la derivata della funzione di costo del modello. Tuttavia
nell'MLP essa dipende sia dai parametri del livello immediatamente precedente
che da tutti i parametri dei livelli più bassi, per ricorsione. Si può pensare
al BackPropagation come a un modo per propagare all'indietro le informazioni
relative all'errore commesso dai nodi di output rispetto ai target del dataset
di addestramento.

L'algoritmo calcola il gradiente della funzione di costo in modo automatico
applicando ricorsivamente lungo il grafo di computazione di $J(\bm \Theta)$ la
regola di derivazione per le funzioni composte: $ (f \circ g)' = (f' \circ
g)\cdot g' $. Esso sfrutta la tecnica della memoizzazione, proria della
programmazione dinamica, per evitare di ricalcolare più volte la derivata di
branch comuni dell'albero di computazione, rendendolo di fatto un metodo molto
efficiente.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Attivazione: ReLU}
Come descritto, la funzione di attivazione conferisce al modello la sua
nonlinearità. Ciò è fondamentale perchè l'MLP riesca ad approssimare funzioni
continue arbitrarie. Se non ci fosse alcuna funzione di attivazione o se questa
fosse lineare rispetto ai parametri del modello, l'output della rete si
potrebbe esprimere come una semplice applicazione lineare, rendendolo di fatto
equivalente a un semplice modello di regressione lineare.

Con l'avvento delle reti neurali profonde e di nuove architetture più
complesse, l'utilizzo delle funzioni di attivazioni logistiche è andato
calando. Una delle cause è il cosiddetto fenomeno del ``vanishing gradient'',
un problema che insorge nel calcolare numericamente il gradiente della funzione
di costo di una rete neurale con molti livelli. In questo caso l'uso della
funzione sigmoidea è in generale sconsigliato poichè il suo valore ``satura'' a
causa dei suoi asintoti e questo rende la sua derivata prossima a zero. Il
metodo del gradiente risulta quindi poco efficace nell'aggiornare i parametri
del modello.  Per questo motivo è stata introdotta la funzione ReLU
(dall'inglese \emph{rectified linear unit}) definita nel modo seguente: $g(x) =
\max\{0, x\}$. L'operazione di rettificazione è mostrata in Figura~%
\ref{fig:relu}.
\begin{figure}[htp]
  \includetikz{0.9}{./img/relu}
  \caption{La funzione di attivazione ReLU}%
  \label{fig:relu}
\end{figure}

L'output del rettificatore, essendo esso quasi una funzione lineare, mantiene
le informazioni del gradiente in modo migliore rispetto al sigmoide,
rendendo la convergenza del metodo del gradiente più veloce.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Reti Neurali Convoluzionali}
Una particolare categoria di reti feed forward è quella delle reti neurali
convoluzionali, o \emph{convolutional neural networks} (CNN) in inglese. Una
CNN non è altro che una rete neurale che adotta l'operazione di
\emph{convoluzione} in almeno uno dei suoi layer, al posto della più comune
moltiplicazione matriciale.

L'operazione di convoluzione, usualmente indicata con il simbolo $*$, è
definita per due funzioni continue $f$ e $g$ come:
\[
(f * g)(t) = \int_{-\infty}^\infty{f(x)k(t - x)dx}
\]
mentre, nel caso discreto, è invece definita nel seguente modo:
\[
(f * g)(t) = \sum_{x = -\infty}^\infty{f(x)k(t - x)}
\]
Poichè in una rete neurale le funzioni $f$ e $g$ sono rappresentate
generalmente da tensori, l'operazione si può limitare ai soli elementi di tali
insiemi di valori, con l'assunzione che le due funzioni siano nulle ovunque
tranne nei punti in cui sono definiti i tensori. Nel caso di input
bidimensionali, come è quello delle immagini, si ha quindi:
\begin{align*}
(X * K)(i,j) &= \sum_m{\sum_n{X(m,n) K(i - m, j - n)}} \\
             &= \sum_m{\sum_n{X(i - m, j - n) K(m, n)}}
\end{align*}
in cui $X$ rappresenta l'input dell'operazione, mentre $K$ è chiamato
\emph{kernel}, o filtro, e costituisce i parametri adattivi della CNN\@. Nella
pratica è tuttavia più comune utilizzare l'operazione di
\emph{cross-correlation}, definita come
\[ (K * X)(i, j) \sum_m{\sum_n{X(i + m, j + n) K(m, n)}} \]
Tale operazione equivale a spostare il filtro $K$ lungo le due dimensioni
dell'input $X$, eseguendo una moltiplicazione elemento per elemento tra i due
tensori e sommandone i risultati. Un esempio è illustrato in
Figura~\ref{fig:conv}.
\begin{figure}[htp]
  \includetikz{1.0}{./img/conv}
  \caption{%
    Spostamento di un filtro $3\times3$ lungo una matrice di dimensioni
    $4\times4$. Nel primo e secondo riquadro il filtro rientra completamente
    nelle dimensioni della matrice, mentre nel terzo caso una colonna risulta
    al di fuori. Gli elementi del filtro che vengono proiettati esternamente
    alla matrice vengono moltiplicati con valori nulli e non contribuiscono al
    valore finale della convoluzione.
  }%
  \label{fig:conv}
\end{figure}
\subsection{Pooling}
L'output della convoluzione è chiamato \emph{feature map} e generalmente ne
vengono calcolate svariate decine per ogni livello, ognuna attraverso
l'applicazione, sullo stesso input, di un filtro diverso. Il numero di feature
map aumenta generalmente con il crescere della profondità della rete. Questo
accade per far fronte alla riduzione dimensionale causata dai livelli di
\emph{pooling}. Questi ultimi hanno lo scopo di rendere il modello parzialmente
invariante rispetto a piccole traslazioni o disturbi nell'input. Ciò avviene
applicando un'operazione di sottocampionamento (\emph{subsampling}) a
sottoinsiemi, disgiunti o no, dell'input del livello. Tale operazione può prevedere la
selezione del massimo degli elementi del sottoinsieme, oppure della loro media
aritmetica. L'operazione di pooling è illustrata in Figura~\ref{fig:pooling}.
\begin{figure}[htp]
  \includetikz{1.0}{./img/pooling}
  \caption{%
    Schematizzazione di un semplice blocco convoluzionale a cui è applicata
    l'operazione di pooling. L'input è bidimensionale e con un solo canale (per
    esempio l'itensità dei pixel di un'immagine in bianco e nero) e vengono
    prodotte \(K\) feature map. Il livello di pooling dimezza le dimensioni
    dell'input.
  }%
  \label{fig:pooling}
\end{figure}

% \section{Regolarizzazione}
% \subsection{Overfitting e Underfitting}
% \subsection{Regolarizzazione L2}
% \subsection{Dropout}

\end{document}

